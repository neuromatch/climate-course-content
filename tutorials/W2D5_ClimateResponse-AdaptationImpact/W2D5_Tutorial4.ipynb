{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neuromatch/climate-course-content/blob/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/W2D5_Tutorial4.ipynb)   <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/tutorials/W2D5_ClimateResponse-AdaptationImpact/W2D5_Tutorial4.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myt07YFyNgmw"
   },
   "source": [
    "# Tutorial 4: Testing Spatial Generalization\n",
    "\n",
    "**Week 2, Day 5, AI and Climate Change**\n",
    "\n",
    "__Content creators:__  Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ Mujeeb Abdulfatai, Nkongho Ayuketang Arreyndip, Jeffrey N. A. Aryee, Paul Heubel, Jenna Pearson, Abel Shibu\n",
    "\n",
    "__Content editors:__ Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos\n",
    "\n",
    "**Our 2024 Sponsors:** CMIP, NFDI4Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDQc1jnoNWcp"
   },
   "source": [
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial:* 20 minutes\n",
    "\n",
    "In this tutorial, you will:   \n",
    "* Learn the concept of within distribution generalization\n",
    "* Test your model’s ability on a certain type of out-of-distribution data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "id": "Vtq0OyoRNPcc"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwsl6-KNNPcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports:\n",
    "\n",
    "import matplotlib.pyplot as plt     # For plotting graphs\n",
    "import pandas as pd                 # For data manipulation\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# import specific machine learning models and tools\n",
    "from sklearn.model_selection import train_test_split      # For splitting dataset into train and test sets\n",
    "from sklearn.ensemble import RandomForestRegressor        # For Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/neuromatch/climate-course-content/main/cma.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRSlfJrugBkf"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "# Load and Prepare the Data\n",
    "url_Climatebench_train_val = \"https://osf.io/y2pq7/download\"  # Dataset URL\n",
    "training_data = pd.read_csv(url_Climatebench_train_val)  # Load the training data from the provided URL\n",
    "training_data.pop('scenario')  # Drop the 'scenario' column as it's just a label and won't be passed into the model\n",
    "target = training_data.pop('tas_FINAL')  # Extract the target variable 'tas_FINAL' which we aim to predict\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy1MFnohgBkf",
    "outputId": "2ac5b07d-14f3-4661-99a5-33753041f580"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# Set a global seed value for reproducibility\n",
    "random_state = 42 # change 42 with any number you like\n",
    "\n",
    "set_seed(seed=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBSog43E5Cmr"
   },
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "# @markdown Run this cell to define plotting function we will be using in this code\n",
    "\n",
    "def visualize_decision_tree(X_train, y_train, X_test, y_test, dt_model):\n",
    "    # Plot decision tree and regression\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot Decision Tree\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_train, y_train, color='blue', label='Training data')\n",
    "    plt.scatter(X_test, y_test, color='green', label='Test data')\n",
    "    plt.plot(np.sort(X_test, axis=0), dt_model.predict(np.sort(X_test, axis=0)), color='red', label='Model')\n",
    "    plt.title('Decision Tree Regression')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Target')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Decision Tree\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_tree(dt_model, filled=True)\n",
    "    plt.title(\"Decision Tree\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_random_forest(X_train, y_train, X_test, y_test, rf_model):\n",
    "    num_trees = len(rf_model.estimators_)\n",
    "    num_cols = min(3, num_trees)\n",
    "    num_rows = (num_trees + num_cols - 1) // num_cols\n",
    "\n",
    "    plt.figure(figsize=(15, 6 * num_rows))\n",
    "\n",
    "    # Plot Random Forest Regression\n",
    "    plt.subplot(num_rows, num_cols, 1)\n",
    "    plt.scatter(X_train, y_train, color='blue', label='Training data')\n",
    "    plt.scatter(X_test, y_test, color='green', label='Test data')\n",
    "    plt.plot(np.sort(X_test, axis=0), rf_model.predict(np.sort(X_test, axis=0)), color='red', label='Model')\n",
    "    plt.title('Random Forest Regression')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Target')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Decision Trees within Random Forest\n",
    "    for i, tree in enumerate(rf_model.estimators_):\n",
    "        plt.subplot(num_rows, num_cols, i + 2)\n",
    "        plot_tree(tree, filled=True)\n",
    "        plt.title(f\"Tree {i+1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spatial_distribution(data, col_name, c_label):\n",
    "    \"\"\"\n",
    "    Plot the spatial distribution of a variable of interest.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing latitude, longitude, and data of interest.\n",
    "        col_name (str): Name of the column containing data of interest.\n",
    "        c_label (str): Label to describe quantity and unit for the colorbar labeling.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # create a xarray dataset from the pandas dataframe\n",
    "    # for convenient plotting with cartopy afterwards\n",
    "    ds = xr.Dataset({col_name: ('points', data[col_name])},\n",
    "                    coords={'lon': ('points', data['lon']),\n",
    "                            'lat': ('points', data['lat'])}\n",
    "                   )\n",
    "    \n",
    "    # create geoaxes\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([0.95*min(ds.lon.values), 1.05*max(ds.lon.values), 0.95*min(ds.lat.values), 1.05*max(ds.lat.values)])\n",
    "    \n",
    "    # add coastlines\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.OCEAN, alpha=0.1)\n",
    "    # add state borders\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='darkgrey')\n",
    "        \n",
    "    # plot the data\n",
    "    p = ax.scatter(ds['lon'], ds['lat'], c=ds[col_name], cmap='coolwarm', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # add a colorbar\n",
    "    cbar = plt.colorbar(p, orientation='vertical')\n",
    "    cbar.set_label(c_label)\n",
    "\n",
    "    # add a grid and labels\n",
    "    ax.gridlines(draw_labels={\"bottom\": \"x\", \"left\": \"y\"})\n",
    "\n",
    "    # add title\n",
    "    plt.title('Spatial Distribution of\\n Annual Mean Anomalies\\n')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581,
     "referenced_widgets": [
      "29b02150b9a7449c8ece8b5582255586",
      "47e76f6e5c61473db13fa5fedf3ccbd9",
      "9827f6174c754c05836afd5921f9d2b8",
      "d7c32e187fb1463eaefddc658e5df842",
      "e726fa44bc8c4ddcb696a64ff8e3ddc3",
      "30d4dab48f54485d82290cbbde3107b6"
     ]
    },
    "id": "Ty1w5xpQbDuW",
    "outputId": "527e9803-fcbb-4782-982d-e731209f134d"
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Testing spatial generalization\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# curriculum or production team will provide these ids\n",
    "video_ids = [('Youtube', 'U8mshdRYwuY'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlndBdbV5iJF",
    "outputId": "46fa6761-3d1e-454a-91c7-38bc56868aae"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"26r8h\"\n",
    "\n",
    "download_link = f\"https://osf.io/download/{link_id}/\"\n",
    "render_link = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\"\n",
    "# @markdown\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: {download_link}\")\n",
    "    display(IFrame(src=f\"{render_link}\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_ievKxmhlwi"
   },
   "source": [
    "In the video, we discussed how we previously tested generalization to unseen data points from the same data distribution (i.e., same region and scenarios). \n",
    "Now we will see if the model generalizes to data from a new region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsQ6bPAMZWmq"
   },
   "source": [
    "# Section 1:  Test generalization to held-out spatial locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVa1vVA1hzIK"
   },
   "source": [
    "## Section 1.1: Load the New Testing Data\n",
    "\n",
    "We will take our random forest model that was trained on data from the region in the blue box and see if it can work well using lat/lon locations that come from the red box. We already have the data from the blue box region loaded, so now we just need to load the data from the red box.\n",
    "\n",
    "<p align='center'><img src='https://github.com/neuromatch/climate-course-content/blob/main/tutorials/static/W2D5_Tutorial4_map.png' alt='W2D5_Tutorial4_map'/></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "-8Mwrm_DiMq4",
    "outputId": "26ed02f6-8e57-4b6f-8b66-361a09f00b2f"
   },
   "outputs": [],
   "source": [
    "# Loading the new Spatial test data\n",
    "\n",
    "url_spatial_test_data = \"https://osf.io/7tr49/download\" # location of test data\n",
    "spatial_test_data = pd.read_csv(url_spatial_test_data)  # Load spatial test data from the provided URL\n",
    "spatial_test_data.pop('scenario')  # drop the `scenario` column from the data as it is just a label, but will not be passed into the model.\n",
    "spatial_test_target = spatial_test_data.pop('tas_FINAL')  # extract the target variable 'tas_FINAL'\n",
    "# display the prepared spatial test data\n",
    "spatial_test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvI4B3n1SOs-"
   },
   "source": [
    "When we plot the temperature distribution over space, we can see that this dataset has a different range of latitude and longitude values than the initial dataset. We use a plotting function `plot_spatial_distribution()` that you completed in Coding Exercise 1.4 of Tutorial 1 that can be found in the *plotting function* of the Setup section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spatial distribution of temperature anomalies for 2015\n",
    "col_name = 'tas_2015'\n",
    "c_label = 'Temperature (K) in 2015'\n",
    "plot_spatial_distribution(spatial_test_data, col_name, c_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFlfyE20iABp"
   },
   "source": [
    "## Section 1.2: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03XnCGUuiucg"
   },
   "source": [
    "We've been playing around with the random forest model parameters. To make sure we know what model we are evaluating, let's train it again here on the training data specifically with `n_estimators = 80` and `max_depth = 50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wloDlpZXVoBU",
    "outputId": "04cffb40-c40a-45c6-912f-4e61ab77260e"
   },
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(random_state=42, n_estimators=80, max_depth=50)\n",
    "# Train the model on the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "train_score = rf_regressor.score(X_train,y_train)\n",
    "test_score = rf_regressor.score(X_test,y_test)\n",
    "print( \"Training Set Score     : \", train_score)\n",
    "print( \"   Test  Set Score     : \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54WjYVeVVwl8"
   },
   "source": [
    "Now that the model has been trained on data from the blue box region, let's test how well it performs on data from the red box region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpTlrQ1YjLOH",
    "outputId": "53343dd1-8da5-4b98-8994-ca5931c61cc0"
   },
   "outputs": [],
   "source": [
    "spatial_test_score = rf_regressor.score(spatial_test_data,spatial_test_target)\n",
    "print( \"Spatial Test Data Score : \", spatial_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZoPCpz_Wn7U"
   },
   "source": [
    "Now it is your turn: Make a scatter plot of the predicted vs true 2050 temperature values for this data, like you did in the last tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qxEjipLnOCq"
   },
   "source": [
    "### Coding Exercise 1.2: Scatter Plot for Spatial data\n",
    "\n",
    "In this exercise implement the `scatter_plot_predicted_vs_true()` function to evaluate the performance of a pre-trained Random Forest regressor model on a new emissions scenario and create a scatter plot of predicted vs. true temperature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_predicted_vs_true(spatial_test_data, true_values):\n",
    "    \"\"\"Create a scatter plot of predicted vs true temperature values.\n",
    "\n",
    "    Args:\n",
    "        spatial_test_data: Test features.\n",
    "        true_values (ndarray): True temperature values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # make predictions using the random forest regressor\n",
    "    spatial_test_predicted = rf_regressor.predict(spatial_test_data)\n",
    "\n",
    "    spatial_test_score = rf_regressor.score(spatial_test_data, true_values)\n",
    "    print(\"\\nSpatial Test Data Score:\", spatial_test_score)\n",
    "\n",
    "    # implement plt.scatter() to compare predicted and true temperature values\n",
    "    _ = ...\n",
    "    # implement plt.plot() to plot the diagonal line y=x\n",
    "    _ = ...\n",
    "\n",
    "    # aesthetics\n",
    "    plt.xlabel('Predicted Temperatures (K)')\n",
    "    plt.ylabel('True Temperatures (K)')\n",
    "    plt.title('Annual mean temperature anomaly')\n",
    "\n",
    "    # add a caption with adjusted y-coordinate to create space\n",
    "    caption_text = 'The anomalies are calculated by subtracting the annual means of the pre-industrial scenario from \\nthe annual means of the respective scenario.'\n",
    "    plt.figtext(0.5, -0.03, caption_text, ha='center', fontsize=10)  # Adjusted y-coordinate to create space\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# test your function\n",
    "_ = scatter_plot_predicted_vs_true(spatial_test_data,spatial_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "25nX8enps5x3",
    "outputId": "e6051384-3cd8-4753-a4e3-559b1db84abd"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def scatter_plot_predicted_vs_true(spatial_test_data, true_values):\n",
    "    \"\"\"Create a scatter plot of predicted vs true temperature values.\n",
    "\n",
    "    Args:\n",
    "        spatial_test_data: Test features.\n",
    "        true_values (ndarray): True temperature values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # make predictions using the random forest regressor\n",
    "    spatial_test_predicted = rf_regressor.predict(spatial_test_data)\n",
    "\n",
    "    spatial_test_score = rf_regressor.score(spatial_test_data, true_values)\n",
    "    print(\"\\nSpatial Test Data Score:\", spatial_test_score)\n",
    "\n",
    "    # implement plt.scatter() to compare predicted and true temperature values\n",
    "    _ = plt.scatter(spatial_test_predicted, true_values, color='b', label='Comparison of Predicted and True Temperatures')\n",
    "    # implement plt.plot() to plot the diagonal line y=x\n",
    "    _ = plt.plot([min(spatial_test_predicted), max(spatial_test_predicted)], [min(true_values), max(true_values)], color='r', label='Ideal Line')\n",
    "    \n",
    "    # aesthetics\n",
    "    plt.xlabel('Predicted Temperatures (K)')\n",
    "    plt.ylabel('True Temperatures (K)')\n",
    "    plt.title('Annual mean temperature anomaly')\n",
    "\n",
    "    # add a caption with adjusted y-coordinate to create space\n",
    "    caption_text = 'The anomalies are calculated by subtracting the annual means of the pre-industrial scenario from \\nthe annual means of the respective scenario.'\n",
    "    plt.figtext(0.5, -0.03, caption_text, ha='center', fontsize=10)  # Adjusted y-coordinate to create space\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# test your function\n",
    "_ = scatter_plot_predicted_vs_true(spatial_test_data,spatial_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3neFX0hcg8i"
   },
   "source": [
    "### Question 1.2: Performance of the model for new spatial location data\n",
    "\n",
    "1. Have you observed the decrease in score?   \n",
    "2. What do you believe could be the cause of this?   \n",
    "3. What do you think would happen if the model was tested on an even farther away region, for example, in North America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "XUPbNQXuwgsy",
    "outputId": "360bf2c6-31ff-486e-ed22-46c1070b5bd3"
   },
   "outputs": [],
   "source": [
    "# to_remove explanation\n",
    "\n",
    "\"\"\"\n",
    "1. Yes, there appears to be a decrease in score when the model is tested on new location data.\n",
    "2. The decrease in score could be attributed to the model's inability to generalize well to new locations.\n",
    " It's possible that the model has learned patterns specific to the training data but fails to capture the nuances present in the new location data.\n",
    "3. If the model was tested on an even farther away region, such as North America,\n",
    " we might expect the performance to deteriorate further. This is because the model was trained on data from a different geographical region,\n",
    " and it may struggle to accurately predict temperatures in regions with vastly different climate patterns and environmental factors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7VAbXQxYiNP"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, you investigated the generalization capacity of machine learning models to novel geographical regions. The process involved assessing model performance on spatial datasets from diverse locations, shedding light on the model's adaptability across varying environmental contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SpKyVbrKzHe"
   },
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [ClimateBench v1.0: A Benchmark for Data-Driven Climate Projections](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021MS002954) \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
