{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/climate-course-content/blob/main/projects/project-notebooks/Heatwaves_project_notebook_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/projects/project-notebooks/Heatwaves_project_notebook_2024.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbNfwh3vgEcU"
   },
   "source": [
    "# Heatwaves\n",
    "\n",
    "**Content creators:** Wil Laura\n",
    "\n",
    "**Content reviewers:** Will Gregory, Paul Heubel, Laura Paccini, Jenna Pearson\n",
    "\n",
    "**Content editors:** Paul Heubel\n",
    "\n",
    "**Production editors:** Paul Heubel, Konstantine Tsafatinos\n",
    "\n",
    "**Our 2024 Sponsors:** CMIP, NFDI4Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "mUt8EEPe0hKk",
    "outputId": "3e1145b7-ff68-4475-d51c-88784416b5e8"
   },
   "outputs": [],
   "source": [
    "# @title Project Background\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')  \n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'aXBq-A8JsPE'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "tX5Bh4Pivakh",
    "outputId": "7036341a-1ed4-420a-b198-cecffce9cc01",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @title Slides\n",
    "# @markdown These are the slides for the video introduction to the project\n",
    "from IPython.display import IFrame\n",
    "link_id = \"zeyxn\"\n",
    "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0arQA56IUtk"
   },
   "source": [
    "**In this project**, you will look into the characterization of heatwaves using near-surface air temperature reanalysis data. Since we are talking about extreme events when the temperature exceeds a certain threshold for a continuous number of days, we will first analyze the global spatial and temporal distribution of air temperature. Next, we will calculate the number and timing of heatwaves for a local area, then focus on determining the percentage of a region under heat waves. Additionally, you will be able to explore its relationship with other climate drivers. Also, you are encouraged to analyze the health impact of heatwaves using an available mortality dataset. Finally, enjoy exploring the heatwaves!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9_7XVXBgLf3"
   },
   "source": [
    "# Project Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT_VUme8iNod"
   },
   "source": [
    "  <img src='../template-images/2024_Heatwaves.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raQmOQkWigMy"
   },
   "source": [
    "# Data Exploration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuozLOtcjL5Q"
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab installs\n",
    "#!pip install pandas==1.5.3\n",
    "\n",
    "# !pip install cartopy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYVofx_Ej0c5",
    "outputId": "1506c899-d979-4b1e-aac4-1e12e2d2f6e1"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "#import xclim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.dates as mdates\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#from xclim.core.calendar import percentile_doy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "import os\n",
    "import pooch\n",
    "import tempfile\n",
    "\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    shared_location = \"/home/jovyan/shared/Data/projects/Heatwaves\"  # this is different for each day\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "import ipywidgets as widgets       # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/neuromatch/climate-course-content/main/cma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FICTmBLTkIPr"
   },
   "source": [
    "## ECMWF Reanalysis v5 (ERA5): Air Temperature at 2m\n",
    "\n",
    "You will utilize the ERA5 dataset to examine temperature trends and heatwaves, applying the loading methods introduced in W1D1. Please, see the W1D2 course material for more information on reanalysis data. Besides, you can read more about ERA5 here: [Climate reanalysis](https://climate.copernicus.eu/climate-reanalysis).\n",
    "\n",
    "Specifically, in this project, you will focus on near-surface temperature, which refers to the temperature of air at $2 \\text{m}$ above the surface of land, sea, or inland waters, temperature with units of Kelvin $\\left(\\text{K}\\right)$.\n",
    "\n",
    "You will access the following subsampled data through the OSF cloud storage to simplify downloading. For the project, it is necessary to download data yourself when you are interested in exploring other regional subsets or variables. Please have a look at the [`get_ERA5_reanalysis_data.ipynb`](https://github.com/neuromatch/climate-course-content/blob/main/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/get_ERA5_reanalysis_data.ipynb) notebook, where we show how to use the Climate Data Store (CDS) API to get a subset of the huge ECMWF ERA5 Reanalysis data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, along with a small subsample file that was downloaded beforehand, we show how to load, explore, and visualize ERA5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_cz1nOyk7fe"
   },
   "outputs": [],
   "source": [
    "# loading a subsample of the ERA5 reanalysis dataset, daily from 1991 to 2000\n",
    "link_id = \"z9xfv\"\n",
    "url_ERA5 = f\"https://osf.io/download/{link_id}/\"\n",
    "#filepath = \"/content/file_sample.nc\"\n",
    "fname_ERA5 = \"file_sample.nc\"\n",
    "\n",
    "ds = xr.open_dataset(pooch_load(url_ERA5, fname_ERA5))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16xyHYikLmrd"
   },
   "source": [
    "Let's visualize the distribution of the annual mean near-surface temperature for the year 2000 in the given area around the equator. After calculating the anomaly according to the hints included in the template, you should be able to visualize the answer to **Question 1** similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "7on_k6PakcVi",
    "outputId": "7c793a9c-c42a-4c35-80ab-12cacadc460b"
   },
   "outputs": [],
   "source": [
    "# calculate the annual average of the year selected\n",
    "year_to_use = ds.t2m.loc[\"2000-01-01\":\"2000-12-31\",:,:].mean(dim=\"time\")\n",
    "year_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "7on_k6PakcVi",
    "outputId": "7c793a9c-c42a-4c35-80ab-12cacadc460b"
   },
   "outputs": [],
   "source": [
    "# plot temperature \n",
    "fig, ax = plt.subplots(1, subplot_kw={'projection':ccrs.PlateCarree()}, layout='constrained')\n",
    "\n",
    "extent = [year_to_use.longitude.min(), year_to_use.longitude.max(), year_to_use.latitude.min(),\n",
    "          year_to_use.latitude.max()]\n",
    "#im = ax.imshow(year_to_use, extent=extent, transform=ccrs.PlateCarree(),cmap=\"coolwarm\")\n",
    "im = year_to_use.plot(ax=ax,\n",
    "                      transform=ccrs.PlateCarree(),\n",
    "                      cmap=\"coolwarm\",\n",
    "                      add_colorbar=False)\n",
    "\n",
    "# add coastlines, labeled gridlines and continent boundaries\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels={\"bottom\": \"x\", \"left\": \"y\"})\n",
    "ax.add_feature(cfeature.BORDERS, linestyle='-.')\n",
    "\n",
    "# create colorbar and set cbar label\n",
    "cbar = plt.colorbar(im, ax=ax, orientation='vertical', shrink=0.9, pad=0.1)\n",
    "cbar.set_label('Air temperature at 2m (K)')\n",
    "\n",
    "# set title\n",
    "plt.title(\"Annual mean temperature in 2000\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPwmRiYClFdf"
   },
   "source": [
    "Additionally, you can calculate the air temperature trend. We choose a longer time period and therefore another subsample from 1991 to 2020, that we load in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_id = \"3xbq8\"\n",
    "fname_ERA5 = \"data_sample_91_20.nc\"\n",
    "ds_long = xr.open_dataset(pooch_load(url_ERA5, fname_ERA5))\n",
    "ds_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "k5D4Vu-9k5ZJ",
    "outputId": "6840837d-eb0e-44b4-b2b5-dfe0195bbad7"
   },
   "outputs": [],
   "source": [
    "# find the last year of the dataset\n",
    "last_year = ds_long['time.year'].max().item()\n",
    "\n",
    "# filter the last 30 years\n",
    "ds_30y = ds_long.sel(time=slice(str(last_year-30+1),str(last_year)))\n",
    "\n",
    "# calculate the mean temperature for each year\n",
    "mean_time_dim = ds_30y['t2m'].resample(time=\"Y\").mean(dim=\"time\")\n",
    "\n",
    "# apply cosine of latitude as weights to the dataset variables\n",
    "weights = np.cos(np.deg2rad(mean_time_dim.latitude))\n",
    "weighted_mean_time_dim = mean_time_dim.weighted(weights)\n",
    "\n",
    "# calculate the global mean in degrees celsius\n",
    "weighted_global_mean_temp = weighted_mean_time_dim.mean(dim=[\"longitude\",\"latitude\"])\n",
    "weighted_global_mean_temp_c = weighted_global_mean_temp - 273.15\n",
    "\n",
    "# calculate the trend line\n",
    "years = weighted_global_mean_temp_c['time'].dt.year.values\n",
    "annual_temperature = weighted_global_mean_temp_c.values\n",
    "trend_coefficients = np.polyfit(years, annual_temperature, 1)\n",
    "trend_line = np.poly1d(trend_coefficients)\n",
    "\n",
    "# draw data\n",
    "plt.plot(years, annual_temperature, color=\"blue\", label=\"ERA5 Reanalysis - annually resampled\")\n",
    "plt.plot(years, trend_line(years), color=\"red\", linestyle=\"--\", label='Trend line')\n",
    "\n",
    "# aesthetics\n",
    "plt.xlabel(\"Time (years)\")\n",
    "plt.ylabel(\"Air temperature at 2m (K)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5-Land hourly data from 1950 to present \n",
    "This [ERA5 Reanalysis dataset](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview) of hourly data has an increased spatial resolution and focuses on the land variable evolution over the last decades. It is updated regularly by ECMWF and accessible via the CDS API (cf. [`get_ERA5_reanalysis_data.ipynb`](https://github.com/neuromatch/climate-course-content/blob/main/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/get_ERA5_reanalysis_data.ipynb)). A similar dataset of lower temporal resolution, i.e. monthly averages can be found [here](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=overview).\n",
    "\n",
    "Depending on your research question it is essential to choose an adequate frequency, however, due to the huge amount of data available, it might become necessary to focus on a regional subset of the ERA5 dataset.\n",
    "\n",
    "In the following, we show how we downloaded global ERA5-Land data via the CDS API to answer **Q2** by calculating global temperature trends. Please note that the API request serves as an example and the downloading process should not be triggered if not necessary. Please think about an adequate frequency and domain of interest beforehand, to request a subset that is sufficient to answer your questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Uncomment the following block after adjusting it according to your research question\n",
    "# and after successfully working through the `get_ERA5_reanalysis_data.ipynb` notebook.\n",
    "\n",
    "#c.retrieve(\n",
    "#    'reanalysis-era5-land',\n",
    "#    {\n",
    "#        'variable': '2m_temperature',\n",
    "#        'year': ['1974', '1975', '1976', '1977', '1978',\n",
    "#                 '1979', '1980', '1981', '1982', '1983',\n",
    "#                 '1984', '1985', '1986', '1987', '1988',\n",
    "#                 '1989', '1990', '1991', '1992', '1993',\n",
    "#                 '1994', '1995', '1996', '1997', '1998',\n",
    "#                 '1999', '2000', '2001', '2002', '2003',\n",
    "#                 '2004', '2005', '2006', '2007', '2008',\n",
    "#                 '2009', '2010', '2011', '2012', '2013',\n",
    "#                 '2014', '2015', '2016', '2017', '2018',\n",
    "#                 '2019', '2020', '2021', '2022', '2023'],\n",
    "#        'month': ['01','02','03','04','05','06','07','08','09','10','11','12'],\n",
    "#        'day': '15',\n",
    "#        'time': '12:00',\n",
    "#        'grid': ['0.4', '0.4'],\n",
    "#        'format': 'grib',\n",
    "#\n",
    "#    },\n",
    "#    'reanalysis-era5-land_1974_2023_04x04.grib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the request code block, we downloaded the 2m_temperature / $\\text{t2m}$ variable from the *reanalysis-era5-land* at noon on every 15th of the month in the last 50 years. In other words, the requested data is not averaged over the whole month but just a sample. To reduce the resolution, we chose a grid of 0.4° in both spatial dimensions. As we want to calculate global trends over the whole time period, this choice should be adequate and save us a few computational-intensive averaging calculations. Furthermore, it helps to emphasize how the downloaded data looks like. \n",
    "\n",
    "The output is given as a file named `reanalysis-era5-land_1974_2023_04x04.grib` in the [`grib`](https://confluence.ecmwf.int/display/CKB/What+are+GRIB+files+and+how+can+I+read+them) format, which needs a small addition in the known file reading method [`xr.open_dataset(path, engine='cfgrib')`](https://docs.xarray.dev/en/stable/generated/xarray.open_dataset.html#xarray.open_dataset), check out [this resource](https://docs.xarray.dev/en/stable/user-guide/io.html#grib-format-via-cfgrib) for more information. Additionally, we get an `idx` file that is experimental and useful if the file is opened more often but can be ignored or deleted.\n",
    "\n",
    "Again we uploaded these files to the OSF cloud for simple data retrieval, and we converted the file format to `.nc` (NetCDF) as an additional option. The following lines help to open both file types.\n",
    "\n",
    "***Note that the frequency of our example file `reanalysis-era5-land_1974_2023_04x04.grib` is monthly and not daily, hence no further question of the template can be answered by using it. Please increase the frequency and spatial resolution, and reduce the domain of interest when downloading the data to allow for investigations of regional heatwaves.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify filename and filetype\n",
    "filetype = 'grib'\n",
    "#filetype = 'nc'\n",
    "fname_ERA5 = f\"reanalysis-era5-land_1974_2023_04x04.{filetype}\"\n",
    " \n",
    "# check whether the specified path/file exists or not (locally or in the JupyterHub)\n",
    "isExist = os.path.exists(fname_ERA5)\n",
    "\n",
    "# load data and create data set\n",
    "if isExist:\n",
    "    _ = print(f'The file {fname_ERA5} exists locally.\\n Loading the data ...\\n')\n",
    "    if filetype == 'grib':\n",
    "        ds_global = xr.open_dataset(fname_ERA5, engine='cfgrib')\n",
    "    elif filetype == 'nc':\n",
    "        ds_global = xr.open_dataset(fname_ERA5)\n",
    "    else:\n",
    "        raise (\"Please choose an appropriate file type: 'nc' or 'grib'.\")\n",
    "\n",
    "else:\n",
    "    _ = print(f'The file {fname_ERA5} does not exist locally and has to be downloaded from OSF.\\nDownloading the data ...\\n')    \n",
    "\n",
    "    # retrieve the grib file from the OSF cloud storage\n",
    "    if filetype == 'grib':\n",
    "        link_id = \"6d9mf\"\n",
    "    elif filetype == 'nc':\n",
    "        link_id = \"8v63z\"\n",
    "    else:\n",
    "        raise (\"Please choose an appropriate file type: 'nc' or 'grib'.\")\n",
    "        \n",
    "    url_grib = f\"https://osf.io/download/{link_id}/\"\n",
    "\n",
    "    # The following line is the correct approach, however, it sometimes raises an error that could not be solved by the curriculum team\n",
    "    # (cf. https://github.com/ecmwf/cfgrib/blob/master/README.rst & https://github.com/pydata/xarray/issues/6512)\n",
    "    # We, therefore, recommend to download the file separately if this EOFError arises. \n",
    "    \n",
    "    fcached = pooch_load(url_grib, fname_ERA5)\n",
    "    \n",
    "    try:\n",
    "        if filetype == 'grib':\n",
    "            ds_global = xr.open_dataset(fcached, engine='cfgrib')\n",
    "        elif filetype == 'nc':\n",
    "            ds_global = xr.open_dataset(fcached)\n",
    "    except EOFError:\n",
    "        print(f'The cached .grib file could not be parsed with Xarray.\\nPlease download the file to your local directory via {url_grib} or download its NetCDF equivalent.')\n",
    "\n",
    "print(ds_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean 2m temperature of 1974 as example\n",
    "t2m_1974 = ds_global.sel(time=slice('1974')).mean(dim='time')\n",
    "_ = t2m_1974[list(t2m_1974.keys())[0]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFB352Tmjil7"
   },
   "source": [
    "## Weekly Mortality Data (Optional)\n",
    "\n",
    "[The Organisation for Economic Co-operation and Development (OECD)](https://en.wikipedia.org/wiki/OECD) provides weekly mortality data for 38 countries. The list of countries can be found in [the OECD data explorer](https://data-explorer.oecd.org/vis?tm=weekly%20mortality&pg=0&hc[Measure]=Mortality&hc[Frequency%20of%20observation]=Weekly&snb=3&df[ds]=dsDisseminateFinalDMZ&df[id]=DSD_HEALTH_MORTALITY%40DF_MORTALITY&df[ag]=OECD.ELS.HD&df[vs]=1.0&pd=2023-W01%2C&dq=.W.M._T._T.&ly[rw]=TIME_PERIOD&ly[cl]=REF_AREA&to[TIME_PERIOD]=false) in the filters section, under *reference area*. This dataset can be used to analyze the impact of heatwaves on health through the general mortality of a country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "qAGgrbtLljHg",
    "outputId": "45bc3215-d89f-418c-b9bd-c7db6d3bd82b"
   },
   "outputs": [],
   "source": [
    "# read the mortality data from a csv file\n",
    "link_id = \"rh3mp\"\n",
    "url = f\"https://osf.io/download/{link_id}/\"\n",
    "#data_mortality = pd.read_csv(\"Weekly_mortality_OECD.csv\")\n",
    "data_mortality = pd.read_csv(url)\n",
    "data_mortality.info()\n",
    "data_mortality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHJ5l944lstE"
   },
   "source": [
    "# Hint for Q3\n",
    "For this question you will calculate the percentiles, you can read more about percentiles [here](https://www.britannica.com/topic/percentile) and e.g. in W2D3 Tutorial 1. \n",
    "Furthermore, as a recommendation for this question, a definition was given to calculate heatwaves, however, there is a great diversity of definitions, you can read about it in the following article: [Perkins & Alexandar (2013)](https://doi.org/10.1175/JCLI-D-12-00383.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU7ut6Zgl6Ml"
   },
   "source": [
    "# Hint for Q4\n",
    "For Question 4, to understand the method of calculating the percentage of an area under heatwaves, please read the following article: [Silva et al. (2022)](https://doi.org/10.1016/j.jenvman.2022.116193)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJwFdRc3l7pv"
   },
   "source": [
    "# Hint for Q5\n",
    "\n",
    "The following articles will be helpful: [Heo & Bell (2019) (not open access) ](http://dx.doi.org/10.1038/s41370-018-0076-3) and [Smith et al. (2012)](https://doi.org/10.1007/s10584-012-0659-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T2EcomF7U9M"
   },
   "source": [
    "# Hint for Q6\n",
    "\n",
    "The following article will be helpful: [Reddy et al. (2022)](https://iopscience.iop.org/article/10.1088/1748-9326/ac3e9a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvVxbZFYfLLK"
   },
   "source": [
    "# Hint for Q7\n",
    "The following article will help you learn about a method to determine the influence of heatwaves on health by analyzing mortality: [Nori-Sarma et al. (2019)](https://doi.org/10.3390/ijerph16122089)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5GaD8vdmOfO"
   },
   "source": [
    "# Further reading\n",
    "\n",
    "\n",
    "*   Geirinhas, J. et al. (2018) ‘Climatic and synoptic  characterization of heat waves in Brazil’, International Journal of Climatology, 38(4), pp. 1760–1776. [doi: 10.1002/joc.5294](https://doi.org/10.1002/joc.5294) (not open access)\n",
    " \n",
    "\n",
    "*   Perkins-Kirkpatrick, S. et al. (2016) ‘Natural hazards in Australia: heatwaves’, Climatic Change. Climatic Change, 139(1), pp. 101–114. [doi: 10.1007/s10584-016-1650-0](https://doi.org/10.1007/s10584-016-1650-0) (not open access)\n",
    "\n",
    "\n",
    "*   Sutanto, S. et al. (2020) ‘Heatwaves, droughts, and fires: Exploring compound and cascading dry hazards at the pan-European scale’, Environment International. Elsevier, 134(March 2019), p. 105276. [doi: 10.1016/j.envint.2019.105276](https://doi.org/10.1016/j.envint.2019.105276)\n",
    "\n",
    "\n",
    "*  Lo, Y. et al. (2022) ‘Estimating heat-related mortality in near real time for national heatwave plans’, Environmental Research Letters, 17(2). [doi: 10.1088/1748-9326/ac4cf4](https://iopscience.iop.org/article/10.1088/1748-9326/ac4cf4)\n",
    "\n",
    "\n",
    "*  Wilks, D. (2020) 'Statistical Methods in the Atmospheric Sciences', Elsevier. Available at: [https://doi.org/10.1016/C2017-0-03921-6](https://doi.org/10.1016/C2017-0-03921-6) (not open access)\n",
    "\n",
    "\n",
    "*   World Meteorological Organization & World Health Organization. (2015) 'Heatwaves and Health\n",
    "Guidance on Warning-System Development'. WMO-No. 1142. Available at: [https://library.wmo.int/idurl/4/54600](https://library.wmo.int/idurl/4/54600)\n",
    "\n",
    "* https://ecmwf-projects.github.io/copernicus-training-c3s/reanalysis-heatwave.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
