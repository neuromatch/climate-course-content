{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada5523b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/climate-course-content/blob/main/projects/project-notebooks/2024_Regional_precipitation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/projects/project-notebooks/2024_Regional_precipitation.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045624d0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Precipitation Variability and Extreme events\n",
    "\n",
    "**Content creators:** Will Gregory, Laura Paccini, Raphael Rocha\n",
    "\n",
    "**Content reviewers:** Paul Heubel, Jenna Pearson\n",
    "\n",
    "**Content editors:** Paul Heubel\n",
    "\n",
    "**Production editors:** Paul Heubel, Konstantine Tsafatinos\n",
    "\n",
    "**Our 2024 Sponsors:** CMIP, NFDI4Earth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da422f",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Project Background\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "    def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "        self.id = id\n",
    "        if source == \"Bilibili\":\n",
    "            src = f\"https://player.bilibili.com/player.html?bvid={id}&page={page}\"\n",
    "        elif source == \"Osf\":\n",
    "            src = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render\"\n",
    "        super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "    tab_contents = []\n",
    "    for i, video_id in enumerate(video_ids):\n",
    "        out = widgets.Output()\n",
    "        with out:\n",
    "            if video_ids[i][0] == \"Youtube\":\n",
    "                video = YouTubeVideo(\n",
    "                    id=video_ids[i][1], width=W, height=H, fs=fs, rel=0\n",
    "                )\n",
    "                print(f\"Video available at https://youtube.com/watch?v={video.id}\")\n",
    "            else:\n",
    "                video = PlayVideo(\n",
    "                    id=video_ids[i][1],\n",
    "                    source=video_ids[i][0],\n",
    "                    width=W,\n",
    "                    height=H,\n",
    "                    fs=fs,\n",
    "                    autoplay=False,\n",
    "                )\n",
    "                if video_ids[i][0] == \"Bilibili\":\n",
    "                    print(\n",
    "                        f\"Video available at https://www.bilibili.com/video/{video.id}\"\n",
    "                    )\n",
    "                elif video_ids[i][0] == \"Osf\":\n",
    "                    print(f\"Video available at https://osf.io/{video.id}\")\n",
    "            display(video)\n",
    "        tab_contents.append(out)\n",
    "    return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', '49XHRe61LI8'), ('Bilibili', 'BV1Au411L7fo')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "    tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fef8b",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Slides\n",
    "# @markdown These are the slides for the video introduction to the project\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"\"\n",
    "\n",
    "download_link = f\"https://osf.io/download/{link_id}/\"\n",
    "render_link = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\"\n",
    "# @markdown\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: {download_link}\")\n",
    "    display(IFrame(src=f\"{render_link}\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b697d5",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**In this project**, you will explore rain gauge and satellite data from the CHIRPS data set to extract rain estimates and land surface reflectance, respectively. These data will enable identification of extreme events in your region of interest. Besides investigating the relationships between these variables, you are encouraged to study the impact of extreme events on changes in vegetation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ae1c9",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Project Template\n",
    "\n",
    "<img src='../template-images/2024_Precipitation.svg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51243f3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Data Exploration Notebook\n",
    "\n",
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab installs\n",
    "\n",
    "# !pip install s3fs boto3 botocore --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e541a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pooch\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "def pooch_load(filelocation=None,filename=None,processor=None):\n",
    "    shared_location='/home/jovyan/shared/Data/Projects/Precipitation' # this is different for each day\n",
    "    user_temp_cache=tempfile.gettempdir()\n",
    "    \n",
    "    if os.path.exists(os.path.join(shared_location,filename)):\n",
    "        file = os.path.join(shared_location,filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(filelocation,known_hash=None,fname=os.path.join(user_temp_cache,filename),processor=processor)\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07545499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "\n",
    "import ipywidgets as widgets       # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/neuromatch/climate-course-content/main/cma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3777f",
   "metadata": {},
   "source": [
    "## CHIRPS Version 2.0 Global Daily 0.25°\n",
    "\n",
    "The Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS) is a high-resolution precipitation dataset developed by the Climate Hazards Group at the University of California, Santa Barbara. It combines satellite-derived precipitation estimates with ground-based station data to provide gridded precipitation data at a quasi-global scale between 50°S-50°N. \n",
    "\n",
    "Read more about CHIRPS here:\n",
    "\n",
    "* [The climate hazards infrared precipitation with stations—a new environmental record for monitoring extremes](https://www.nature.com/articles/sdata201566)\n",
    "\n",
    "* [Climate Hazard Group CHG Wiki](https://wiki.chc.ucsb.edu/CHIRPS_FAQ)\n",
    "\n",
    "* [Data storage location](https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p25/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36c1fa",
   "metadata": {},
   "source": [
    "### Indices for Extreme Events\n",
    "The Expert Team on Climate Change Detection and Indices ([ETCCDI]( http://etccdi.pacificclimate.org/list_27_indices.shtml)) has defined various indices that focus on different aspects such as duration or intensity of extreme events. The following functions provide examples of how to compute indices for each category. You can modify these functions to suit your specific needs or create your own custom functions. Here are some tips you can use:\n",
    "\n",
    "- Most of the indices require daily data, so in order to select a specific season you can just use `xarray` to subset the data. Example:\n",
    "\n",
    "```python\n",
    "daily_precip_DJF = data_chirps.sel(time=data_chirps['time.season']=='DJF')\n",
    "```\n",
    "\n",
    "- A common threshold for a wet event is precipitation greater than or equal to $1 \\text{ mm}/\\text{day}$, while a dry (or non-precipitating) event is defined as precipitation less than $1 \\text{ mm}/\\text{day}$.\n",
    "- Some of the indices are based on percentiles. You can define a base period climatology to calculate percentile thresholds, such as the 5th, 10th, 90th, and 95th percentiles, to determine extreme events (cf. in particular W2D3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9697620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cdd_index(data):\n",
    "    \"\"\"\n",
    "    This function takes a daily precipitation dataset as input and calculates\n",
    "    the Consecutive Dry Days (CDD) index, which represents the longest sequence\n",
    "    of consecutive days with precipitation less than 1mm. The input data should\n",
    "    be a DataArray with time coordinates, and the function returns a DataArray\n",
    "    with the CDD values for each unique year in the input data.\n",
    "    Parameters:\n",
    "    ----------\n",
    "      - data (xarray.DataArray): The input daily precipitation data should be\n",
    "      a dataset (eg. for chirps_data the DataArray would be chirps_data.precip)\n",
    "    Returns:\n",
    "    -------\n",
    "      - cdd (xarray.DataArray): The calculated CDD index\n",
    "\n",
    "    \"\"\"\n",
    "    # create a boolean array for dry days (PR < 1mm)\n",
    "    dry_days = data < 1\n",
    "    # initialize CDD array\n",
    "    cdd = np.zeros(len(data.groupby(\"time.year\")))\n",
    "    # get unique years as a list\n",
    "    unique_years = list(data.groupby(\"time.year\").groups.keys())\n",
    "    # iterate for each day\n",
    "    for i, year in enumerate(unique_years):\n",
    "        consecutive_trues = []\n",
    "        current_count = 0\n",
    "        for day in dry_days.sel(time=data[\"time.year\"] == year).values:\n",
    "            if day:\n",
    "                current_count += 1\n",
    "            else:\n",
    "                if current_count > 0:\n",
    "                    consecutive_trues.append(current_count)\n",
    "                    current_count = 0\n",
    "        if current_count > 0:\n",
    "            consecutive_trues.append(current_count)\n",
    "        # print(consecutive_trues)\n",
    "        # CDD is the largest number of consecutive days\n",
    "        cdd[i] = np.max(consecutive_trues)\n",
    "    # transform to dataset\n",
    "    cdd_da = xr.DataArray(cdd, coords={\"year\": unique_years}, dims=\"year\")\n",
    "    return cdd_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad439e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to retrieve and load the data\n",
    "\n",
    "years = range(1981,2024) # the years you want. we want 1981 till 2023\n",
    "file_paths = ['https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p25/chirps-v2.0.' + str(year) + '.days_p25.nc' for year in years] # the format of the files\n",
    "filenames = ['chirps-v2.0.'+str(year)+'.days_p25.nc' for year in years] # the format of the files\n",
    "\n",
    "downloaded_files=[ pooch_load(fpath,fname) for (fpath,fname) in zip(file_paths,filenames)] # download all of the files\n",
    "\n",
    "#### open data via xarray\n",
    "chirps_data = xr.open_mfdataset(\n",
    "    downloaded_files, combine=\"by_coords\"\n",
    ")  # open the files as one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f8525",
   "metadata": {},
   "source": [
    "We can now visualize the content of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to print the shape, array names, etc of the dataset\n",
    "chirps_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb296a",
   "metadata": {},
   "source": [
    "## NOAA Fundamental Climate Data Records (FCDR) AVHRR Land Bundle - Normalized Difference Vegetation Index\n",
    "\n",
    "As we learned in the W1D3 tutorials, all the National Atmospheric and Oceanic Administration Climate Data Record (NOAA-CDR) datasets are available both at NOAA National Centers for Environmental Information (NCEI) and commercial cloud platforms. See the link [here](https://registry.opendata.aws/noaa-cdr-terrestrial/). We are accessing the data directly via the [Amazon Web Service (AWS) cloud storage space](https://noaa-cdr-ndvi-pds.s3.amazonaws.com/index.html).\n",
    "\n",
    "For this project, we recommend using the Normalized Difference Vegetation Index (NDVI). It is one of the most commonly used remotely sensed indices. It measures the \"greenness\" of vegetation and is useful in understanding vegetation density and assessing changes in plant health. For example, NDVI can be used to study the impacts of droughts, heatwaves, and insect infestations on plants covering Earth's surface. A good overview of this index from this particular sensor can be accessed [here](https://digitalcommons.unl.edu/nasapub/217/).\n",
    "\n",
    "Recall what we learned in W1D3 Tutorial 3, the data files on AWS are named systematically:\n",
    "\n",
    "> Sensor name: `AVHRR`  \n",
    "> Product category: `Land`  \n",
    "> Product version: `v005`  \n",
    "> Product code: `AVH13C1`  \n",
    "> Satellite platform: `NOAA-07`  \n",
    "> Date of the data: `19810624`  \n",
    "> Processing time: `c20170610041337` (*This will change for each file based on when the file was processed*)  \n",
    "> File format: `.nc` (*netCDF-4 format*)\n",
    "\n",
    "In other words, if we are looking for the data of a specific day, we can easily locate where the file might be. \n",
    "\n",
    "For example, if we want to find the AVHRR data for the day of *2002-03-12 (or March 12, 2002)*, you can use:\n",
    "\n",
    "`s3://noaa-cdr-ndvi-pds/data/2002/AVHRR-Land_v005_AVH13C1_*_20020312_c*.nc`\n",
    "\n",
    "The reason that we put `*` in the above directory is that we are not sure about what satellite platform this data is from and when the data was processed. The `*` is called a **wildcard**, and is used because we want *all* the files that contain our specific criteria, but do not want to have to specify all the other pieces of the filename we are not sure about yet. It should return all the data satisfying that initial criteria and you can refine further once you see what is available. Essentially, this first step helps to narrow down the data search. You can then use this to create datasets from the timeframe of your choosing.\n",
    "\n",
    "*Note the download might take up to hours depending on your time frame of interest and your device. Choose your time frame wisely before taking action to avoid unnecessary data retrieval amounts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access the data similar to Tutorial 3 of W1D3\n",
    "# to access the NDVI data from AWS S3 bucket, we first need to connect to s3 bucket\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "client = boto3.client('s3', config=botocore.client.Config(signature_version=botocore.UNSIGNED)) # initialize aws s3 bucket client\n",
    "# choose a date of interest, we pick its year or month while defining the file_location\n",
    "date_sel = datetime.datetime(2001,1,1,0) \n",
    "\n",
    "file_location = fs.glob('s3://noaa-cdr-ndvi-pds/data/'\n",
    "                        + date_sel.strftime('%Y')\n",
    "                        + '/AVHRR-Land_v005_AVH13C1_*'\n",
    "                        + date_sel.strftime(\"%Y%m\") # or \"%Y\" for the whole Year\n",
    "                        + '*_c*.nc') # the files we want for a whole year/month\n",
    "# load the files, which might take up to a few hours depending on your device, in the JupyterHub it usually faster\n",
    "files_for_pooch=[pooch_load('http://s3.amazonaws.com/'+ file, file) for file in file_location]\n",
    "\n",
    "ds = xr.open_mfdataset(files_for_pooch, combine=\"by_coords\", decode_times=False)  # open the file\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453828b-1200-4ddf-b8ab-abc428e9b375",
   "metadata": {},
   "source": [
    "If the above downloading procedure is not working as expected, please retrieve the following sample to execute the remaining cells of the notebook. Ask for the help of your project TA to download your data of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b70d6-e52c-4131-bd2d-3505f22bd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to get a subsample of AVHRR-Land_v005_AVH13C1_NOAA-16 NDVI data if data retrieval above is not working properly\n",
    "\n",
    "#fname_ndvi_200101 = 'AVHRR-Land_v005_AVH13C1_NOAA-16_200101.nc'\n",
    "#link_id_ndvi = \"a9v7h\"\n",
    "#url_ndvi_200101 = f\"https://osf.io/download/{link_id_ndvi}/\"\n",
    "#\n",
    "#ds = xr.open_dataset(pooch_load(url_ndvi_200101, fname_ndvi_200101))\n",
    "#ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a800d-e83e-422b-ae96-e16bb235e609",
   "metadata": {},
   "source": [
    "*Note that the downloaded satellite data is quality-controlled and flagged accordingly. Please refer to W1D3 Tutorial 3 and others to decipher it. Choose the feasible helper functions, e.g. `get_quality_info_AVHRR(QA)` depending on the sensor of interest. VIIRS is a state-of-the-art sensor that produces measurements that have been available since 2014.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d05ba-643f-4886-919c-2bf7fce08193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVHRR: function to extract high-quality NDVI data\n",
    "def get_quality_info_AVHRR(QA):\n",
    "    \"\"\"\n",
    "    QA: the QA value read in from the NDVI data\n",
    "\n",
    "    High-quality NDVI should meet the following criteria:\n",
    "    Bit 7: 1 (All AVHRR channels have valid values)\n",
    "    Bit 2: 0 (The pixel is not covered by cloud shadow)\n",
    "    Bit 1: 0 (The pixel is not covered by cloud)\n",
    "    Bit 0: \n",
    "\n",
    "    Output:\n",
    "    True: high quality\n",
    "    False: low quality\n",
    "    \"\"\"\n",
    "    # unpack quality assurance flag for cloud (byte: 1)\n",
    "    cld_flag = (QA % (2**2)) // 2\n",
    "    # unpack quality assurance flag for cloud shadow (byte: 2)\n",
    "    cld_shadow = (QA % (2**3)) // 2**2\n",
    "    # unpack quality assurance flag for AVHRR values (byte: 7)\n",
    "    value_valid = (QA % (2**8)) // 2**7\n",
    "\n",
    "    mask = (cld_flag == 0) & (cld_shadow == 0) & (value_valid == 1)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a41745-170f-4902-b680-674e25bf7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the quality assurance value from NDVI data\n",
    "QA = ds.QA\n",
    "\n",
    "# create the high quality information mask\n",
    "mask = get_quality_info_AVHRR(QA)\n",
    "\n",
    "# check the quality flag mask information\n",
    "#mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07685f-f0a6-4e1f-8d5b-3d852f3b808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask ndvi data \n",
    "ndvi_masked = ds.NDVI.where(mask)\n",
    "ndvi_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5b584-18fc-45af-9c47-c118353d4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw data to an example plot\n",
    "ndvi_masked.isel(time=30).coarsen(latitude=10).mean().coarsen(longitude=20).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ab262",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## FAO Data: Cereal Production\n",
    "\n",
    "Cereal production is a crucial component of global agriculture and food security. The [Food and Agriculture Organization](https://www.fao.org/faostat/en/#data/QCL) collects and provides data on cereal production, which includes crops such as wheat, rice, maize, barley, oats, rye, sorghum, millet, and mixed grains. The data covers various indicators such as production quantity, area harvested, yield, and production value.\n",
    "\n",
    "The FAO also collects data on \"area harvested\", which refers to the area of land that is being used to grow cereal crops. This information can be valuable for assessing the productivity and efficiency of cereal production systems in different regions, as well as identifying potential areas for improvement. Overall, the FAO's data on cereal production and land under cereals production is an important resource for policymakers, researchers, and other stakeholders who are interested in understanding global trends in agriculture and food security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2359308",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_cereal = 'data_cereal_land.csv'\n",
    "\n",
    "url_cereal = 'https://raw.githubusercontent.com/Sshamekh/Heatwave/f85f43997e3d6ae61e5d729bf77cfcc188fbf2fd/data_cereal_land.csv'\n",
    "\n",
    "path_cereal = 'shared/data/'\n",
    "if os.path.exists(path_cereal + filename_cereal):\n",
    "    ds_cereal_land = pd.read_csv(path_cereal + filename_cereal)\n",
    "else:\n",
    "    ds_cereal_land = pd.read_csv(pooch_load(url_cereal,filename_cereal))\n",
    "\n",
    "ds_cereal_land.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "country = 'Brazil'\n",
    "unit = 'MT' # metric tons\n",
    "\n",
    "ds_cereal_land_brazil = ds_cereal_land[\n",
    "(ds_cereal_land[\"Country Name\"] == country) & (ds_cereal_land[\"Series Code\"] == f'AG.PRD.CREL.{unit}')\n",
    "].drop(\n",
    "    ['Country Name', 'Country Code', 'Series Name', 'Series Code'], axis=1\n",
    ").reset_index( drop=True ).transpose()\n",
    "\n",
    "ds_cereal_land_brazil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4f21b",
   "metadata": {},
   "source": [
    "We can now visualize the content of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbed1e8-0dec-486b-b2bb-2c8506c1a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "plt.plot(np.arange(1972,2021,1),ds_cereal_land_brazil[1:].astype(float).values)\n",
    "\n",
    "# aesthetics\n",
    "plt.title(f'{country}')\n",
    "plt.xlabel(f'Time (years)')\n",
    "plt.ylabel(f'Cereal production ({unit})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b122",
   "metadata": {},
   "source": [
    "Now you are all set to address the questions you are interested in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1aae5-2286-4c4c-873a-c8bcb3e44e13",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "Plot the annual mean of precipitation for three example years (e.g., 2001, 2005, 2016) using the CHIRPS data sets.\n",
    "\n",
    "*Hint: Check out the tutorials from [W1D1 (e.g. T4)](https://comptools.climatematch.io/tutorials/W1D1_ClimateSystemOverview/student/W1D1_Tutorial4.html#section-2-aggregation-methods), [W1D2 (e.g. T2)](https://comptools.climatematch.io/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/student/W1D2_Tutorial2.html#section-3-plotting-time-series-of-reanalysis-data) and [W1D3 (e.g. T5)](https://comptools.climatematch.io/tutorials/W1D3_RemoteSensingLandOceanandAtmosphere/student/W1D3_Tutorial5.html#section-2-2-global-mean) to recall averaging with `xarray`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356909bc-d52a-4c4c-9bb0-febf2b5979b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Q2\n",
    "Plot the global mean of land precipitation as a function of time for the last 40 years.\n",
    "\n",
    "*Hint: Check out the tutorials that contain time series calculations e.g. from [W1D2 (e.g. T1)](https://comptools.climatematch.io/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/student/W1D2_Tutorial1.html#section-2-3-compute-the-climatology-and-anomalies), [W1D3 (e.g. T5)](https://comptools.climatematch.io/tutorials/W1D3_RemoteSensingLandOceanandAtmosphere/student/W1D3_Tutorial5.html#section-2-2-global-mean) and [W1D5 (e.g. T8)](https://comptools.climatematch.io/tutorials/W1D5_ClimateModeling/student/W1D5_Tutorial8.html).*\n",
    "\n",
    "Compute seasonal means for June-August (JJA) and December-February (DJF).\n",
    "\n",
    "*Hint: Check out the code snippet in the **Indices for Extreme Events** section of this notebook. Furthermore, recall [Tutorial 5 of W1D1](https://comptools.climatematch.io/tutorials/W1D1_ClimateSystemOverview/student/W1D1_Tutorial5.html#section-1-groupby-split-apply-combine)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8a45a-d2ba-4e02-b0a7-036192fdb0e9",
   "metadata": {},
   "source": [
    "# Q3\n",
    "Repeat the analysis in Q2 for a selected region of interest. How does this compare with the respective mean precipitation in the northern and southern hemispheres? How does this compare to the global mean?\n",
    "\n",
    "*Hint: Check out tutorials that showed how to select certain regions of interest, e.g. [T8 and T9 of W1D1](https://comptools.climatematch.io/tutorials/W1D1_ClimateSystemOverview/student/W1D1_Tutorial9.html#section-3-using-where-with-specific-coordinates), [T1 of W1D2](https://comptools.climatematch.io/tutorials/W1D2_StateoftheClimateOceanandAtmosphereReanalysis/student/W1D2_Tutorial1.html) and others.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0607dde-7c65-4ec7-a11b-b8185e33ad19",
   "metadata": {},
   "source": [
    "# Q4\n",
    "Examine the time series in your region of interest and identify extreme values. \n",
    "\n",
    "*Hint: Select a method from a predefined list of indices (provided above in Section **Indices for Extreme Events**) based on relative or absolute thresholds.*\n",
    "\n",
    "Do extreme events occur more often in wet or dry seasons? \n",
    "\n",
    "*Hint: We briefly discussed wet and dry season differences in [Tutorial 4 of W1D3](https://comptools.climatematch.io/tutorials/W1D3_RemoteSensingLandOceanandAtmosphere/student/W1D3_Tutorial4.html#questions-2-2-climate-connection) already, however for another data set of monthly frequency namely the Global Precipitation Climatology Project (GPCP) Monthly Precipitation Climate Data Record (CDR) ([cf. Tutorial 4 of W1D3](https://comptools.climatematch.io/tutorials/W1D3_RemoteSensingLandOceanandAtmosphere/student/W1D3_Tutorial4.html#section-1-obtain-monthly-precipitation-data)). You also examined extreme events on W2D3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a0f3e",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b7ff3",
   "metadata": {
    "execution": {}
   },
   "source": [
    "- Anyamba, A. and Tucker, C.J., 2012. Historical perspective of AVHRR NDVI and vegetation drought monitoring. Remote sensing of drought: innovative monitoring approaches, 23, pp.20. [https://digitalcommons.unl.edu/nasapub/217/](https://digitalcommons.unl.edu/nasapub/217/)\n",
    "- Zhang, X., Alexander, L., Hegerl, G.C., Jones, P., Tank, A.K., Peterson, T.C., Trewin, B. and Zwiers, F.W., 2011. Indices for monitoring changes in extremes based on daily temperature and precipitation data. Wiley Interdisciplinary Reviews: Climate Change, 2(6), pp.851-870. [doi.org/10.1002/wcc.147](https://doi.org/10.1002/wcc.147)\n",
    "- Schultz, P. A., and M. S. Halpert, 1993. Global correlation of temperature, NDVI and precipitation. Advances in Space Research 13(5). pp.277-280. [doi.org/10.1016/0273-1177(93)90559-T](https://doi.org/10.1016/0273-1177(93)90559-T)\n",
    "- Seneviratne, S.I. et al., 2021: Weather and Climate Extreme Events in a Changing Climate. In Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change [Masson-Delmotte, V. et al. (eds.)]. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA, pp.1513–1766, [https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-11/](https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-11/)\n",
    "- IPCC, 2021: Annex VI: Climatic Impact-driver and Extreme Indices [Gutiérrez J.M. et al.(eds.)]. In Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change [Masson-Delmotte, V. et al. (eds.)]. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA, pp. 2205–2214, [https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_AnnexVI.pdf](https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_AnnexVI.pdf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Example_based_on_CMA_structure",
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
