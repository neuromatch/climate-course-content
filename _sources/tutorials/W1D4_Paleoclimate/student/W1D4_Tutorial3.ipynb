{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neuromatch/climate-course-content/blob/main/tutorials/W1D4_Paleoclimate/student/W1D4_Tutorial3.ipynb)   <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/tutorials/W1D4_Paleoclimate/student/W1D4_Tutorial3.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 3: Reconstructing Past Changes in Terrestrial Climate\n",
    "\n",
    "**Week 1, Day 4, Paleoclimate**\n",
    "\n",
    "**Content creators:** Sloane Garelick\n",
    "\n",
    "**Content reviewers:** Yosmely Bermúdez, Dionessa Biton, Katrina Dobson, Maria Gonzalez, Will Gregory, Nahid Hasan, Paul Heubel, Sherry Mi, Beatriz Cosenza Muralles, Brodie Pearson, Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Content editors:** Yosmely Bermúdez, Paul Heubel, Zahra Khodakaramimaghsoud, Jenna Pearson, Agustina Pesce, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Production editors:** Wesley Banfield, Paul Heubel, Jenna Pearson, Konstantine Tsafatinos, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Our 2024 Sponsors:** CMIP, NFDI4Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial:* 20 minutes\n",
    "\n",
    "In this tutorial, we’ll explore the Euro2K proxy network, which is a subset of PAGES2K, the database we explored in the first tutorial. We will specifically focus on interpreting temperature change over the past 2,000 years as recorded by proxy records from tree rings, speleothems, and lake sediments. To analyze these datasets, we will group them by archive and create time series plots to assess temperature variations.\n",
    "\n",
    "During this tutorial, you will:\n",
    "\n",
    "- Plot temperature records based on three different terrestrial proxies\n",
    "- Assess similarities and differences between the temperature records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# installations ( uncomment and run this cell ONLY when using google colab or kaggle )\n",
    "\n",
    "# !pip install LiPD\n",
    "# !pip install cartopy\n",
    "# !pip install pyleoclim==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyleoclim as pyleo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pooch\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from io import StringIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install and import feedback gadget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip3 install vibecheck datatops --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"comptools_4clim\",\n",
    "            \"user_key\": \"l5jpxuee\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D4_T3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/neuromatch/climate-course-content/main/cma.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    # this is different for each day\n",
    "    shared_location = \"/home/jovyan/shared/Data/tutorials/W1D4_Paleoclimate\"\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "class SupressOutputs(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio  # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: Terrestrial Climate Proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Terrestrial Climate Proxies\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "    def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "        self.id = id\n",
    "        if source == \"Bilibili\":\n",
    "            src = f\"https://player.bilibili.com/player.html?bvid={id}&page={page}\"\n",
    "        elif source == \"Osf\":\n",
    "            src = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render\"\n",
    "        super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "    tab_contents = []\n",
    "    for i, video_id in enumerate(video_ids):\n",
    "        out = widgets.Output()\n",
    "        with out:\n",
    "            if video_ids[i][0] == \"Youtube\":\n",
    "                video = YouTubeVideo(\n",
    "                    id=video_ids[i][1], width=W, height=H, fs=fs, rel=0\n",
    "                )\n",
    "                print(f\"Video available at https://youtube.com/watch?v={video.id}\")\n",
    "            else:\n",
    "                video = PlayVideo(\n",
    "                    id=video_ids[i][1],\n",
    "                    source=video_ids[i][0],\n",
    "                    width=W,\n",
    "                    height=H,\n",
    "                    fs=fs,\n",
    "                    autoplay=False,\n",
    "                )\n",
    "                if video_ids[i][0] == \"Bilibili\":\n",
    "                    print(\n",
    "                        f\"Video available at https://www.bilibili.com/video/{video.id}\"\n",
    "                    )\n",
    "                elif video_ids[i][0] == \"Osf\":\n",
    "                    print(f\"Video available at https://osf.io/{video.id}\")\n",
    "            display(video)\n",
    "        tab_contents.append(out)\n",
    "    return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [(\"Youtube\", \"wU2gNOYOXrQ\"), (\"Bilibili\", \"BV1s94y1B7Yx\")]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "    tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Terrestrial_Climate_Proxies_Video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"6gcsh\"\n",
    "\n",
    "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Terrestrial_Climate_Proxies_Slides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 1: Loading Terrestrial Paleoclimate Records\n",
    "\n",
    "First, we need to download the data. Similar to Tutorial 1, the data is stored as a LiPD file, and we will be using Pyleoclim to format and interpret the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# set the name to save the Euro2k data\n",
    "fname = \"euro2k_data\"\n",
    "\n",
    "# download the data\n",
    "lipd_file_path = pooch.retrieve(\n",
    "    url=\"https://osf.io/7ezp3/download/\",\n",
    "    known_hash=None,\n",
    "    path=\"./\",\n",
    "    fname=fname,\n",
    "    processor=pooch.Unzip(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# the LiPD object can be used to load datasets stored in the LiPD format.\n",
    "# in this first case study, we will load an entire library of LiPD files:\n",
    "with SupressOutputs():\n",
    "    d_euro = pyleo.Lipd(os.path.join(\".\", f\"{fname}.unzip\", \"Euro2k\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 2: Temperature Reconstructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Before plotting, let's narrow the data down a bit. We can filter all of the data so that we only keep reconstructions of temperature from terrestrial archives (e.g. tree rings, speleothems and lake sediments). This is accomplished with the function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def filter_data(dataset, archive_type, variable_name):\n",
    "    \"\"\"\n",
    "    Return a MultipleSeries object with the variable record (variable_name) for a given archive_type and coordinates.\n",
    "    \"\"\"\n",
    "    # Create a list of dictionary that can be iterated upon using Lipd.to_tso method\n",
    "    ts_list = dataset.to_tso()\n",
    "    # Append the correct indices for a given value of archive_type and variable_name\n",
    "    indices = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    for idx, item in enumerate(ts_list):\n",
    "        # Check that it is available to avoid errors on the loop\n",
    "        if \"archiveType\" in item.keys():\n",
    "            # If it's a archive_type, then proceed to the next step\n",
    "            if item[\"archiveType\"] == archive_type:\n",
    "                if item[\"paleoData_variableName\"] == variable_name:\n",
    "                    indices.append(idx)\n",
    "    print(indices)\n",
    "    # Create a list of LipdSeries for the given indices\n",
    "    ts_list_archive_type = []\n",
    "    for indice in indices:\n",
    "        ts_list_archive_type.append(pyleo.LipdSeries(ts_list[indice]))\n",
    "\n",
    "        # save lat and lons of proxies\n",
    "        lat.append(ts_list[indice][\"geo_meanLat\"])\n",
    "        lon.append(ts_list[indice][\"geo_meanLon\"])\n",
    "\n",
    "    return pyleo.MultipleSeries(ts_list_archive_type), lat, lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the function above, the [`Lipd.to_tso()`](https://pyleoclim-util.readthedocs.io/en/latest/core/api.html#pyleoclim.core.lipd.Lipd.to_tso) method is used to obtain a list of dictionaries that can be iterated upon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "ts_list = d_euro.to_tso()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Dictionaries are native to Python and can be explored as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# look at available entries for just one time-series\n",
    "ts_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# print relevant information for all entries\n",
    "for idx, item in enumerate(ts_list):\n",
    "    print(str(idx) + \": \" + item[\"dataSetName\"] +\n",
    "          \": \" + item[\"paleoData_variableName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now let's use our pre-defined function to create a new list that only has temperature reconstructions based on proxies from **lake sediments**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1680674812384,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_lake, euro_lake_lat, euro_lake_lon = filter_data(\n",
    "    d_euro, \"lake sediment\", \"temperature\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "And a new list that only has temperature reconstructions based on proxies from **tree rings**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1680674816989,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_tree, euro_tree_lat, euro_tree_lon = filter_data(\n",
    "    d_euro, \"tree\", \"temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "And finally, a new list that only has temperature information based on proxies from **speleothems**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1680674825774,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "ms_euro_spel, euro_spel_lat, euro_spel_lon = filter_data(\n",
    "    d_euro, \"speleothem\", \"d18O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercises 2\n",
    "\n",
    "Using the coordinate information output from the `filter_data()` function, make a plot of the locations of the proxies using the markers and colors from Tutorial 1. Note that data close together may not be very visible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure()\n",
    "\n",
    "# set base map projection\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "\n",
    "ax.set_global()\n",
    "\n",
    "# add land fratures using gray color\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"k\")\n",
    "\n",
    "# add coastlines\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "#################################################\n",
    "## TODO for students: add the proxy locations ##\n",
    "# Remove or comment the following line of code once you have completed the exercise:\n",
    "raise NotImplementedError(\"Student exercise: Add the proxy locations via a scatter plot method.\")\n",
    "#################################################\n",
    "# add the proxy locations\n",
    "_ = ax.scatter(\n",
    "    ...,\n",
    "    ...,\n",
    "    transform=ccrs.Geodetic(),\n",
    "    label=...,\n",
    "    s=50,\n",
    "    marker=\"d\",\n",
    "    color=[0.52734375, 0.8046875, 0.97916667],\n",
    "    edgecolor=\"k\",\n",
    "    zorder=2,\n",
    ")\n",
    "_ = ax.scatter(\n",
    "    ...,\n",
    "    ...,\n",
    "    transform=ccrs.Geodetic(),\n",
    "    label=...,\n",
    "    s=50,\n",
    "    marker=\"p\",\n",
    "    color=[0.73828125, 0.71484375, 0.41796875],\n",
    "    edgecolor=\"k\",\n",
    "    zorder=2,\n",
    ")\n",
    "_ = ax.scatter(\n",
    "    ...,\n",
    "    ...,\n",
    "    transform=ccrs.Geodetic(),\n",
    "    label=...,\n",
    "    s=50,\n",
    "    marker=\"8\",\n",
    "    color=[1, 0, 0],\n",
    "    edgecolor=\"k\",\n",
    "    zorder=2,\n",
    ")\n",
    "\n",
    "# change the map view to zoom in on central Pacific\n",
    "ax.set_extent((0, 360, 0, 90), crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.legend(\n",
    "    scatterpoints=1,\n",
    "    bbox_to_anchor=(0, -0.4),\n",
    "    loc=\"lower left\",\n",
    "    ncol=3,\n",
    "    fontsize=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/climate-course-content/tree/main/tutorials/W1D4_Paleoclimate/solutions/W1D4_Tutorial3_Solution_ead41c6f.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=775.0 height=277.0 src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/tutorials/W1D4_Paleoclimate/static/W1D4_Tutorial3_Solution_ead41c6f_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercises_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Since we are going to compare temperature datasets based on different terrestrial climate archives (lake sediments, tree rings and speleothems), the quantitative values of the measurements in each record will differ (i.e., the lake sediment and tree ring data are temperature in degrees C, but the speleothem data is oxygen isotopes in per mille). Therefore, to more easily and accurately compare temperature between the records, it's helpful to standardize the data as we did in Tutorial 2. The [`.standardize()`](https://pyleoclim-util.readthedocs.io/en/v0.7.4/core/ui.html#pyleoclim.core.ui.Series.standardize) function removes the estimated mean of the time series and divides by its estimated standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "spel_stnd = ms_euro_spel.standardize()\n",
    "lake_stnd = ms_euro_lake.standardize()\n",
    "tree_stnd = ms_euro_tree.standardize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can use Pyleoclim functions to create three stacked plots of this data with lake sediment records on top, tree ring reconstructions in the middle and speleothem records on the bottom.\n",
    "\n",
    "Note that the colors used for the time series in each plot are the default colors generated by the function, so the corresponding colors in each of the three plots are not relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 4905,
     "status": "ok",
     "timestamp": 1680674844494,
     "user": {
      "displayName": "Brodie Pearson",
      "userId": "05269028596972519847"
     },
     "user_tz": 420
    }
   },
   "outputs": [],
   "source": [
    "# note the x-axis is years before present,\n",
    "# so reading from left to right corresponds to moving back in time\n",
    "\n",
    "ax = lake_stnd.stackplot(\n",
    "    label_x_loc=1.7,\n",
    "    xlim=[0, 2000],\n",
    "    v_shift_factor=1,\n",
    "    figsize=[9, 5],\n",
    "    time_unit=\"yrs BP\",\n",
    ")\n",
    "ax[0].suptitle(\"Lake Cores\", y=1.2)\n",
    "\n",
    "ax = tree_stnd.stackplot(\n",
    "    label_x_loc=1.7,\n",
    "    xlim=[0, 2000],\n",
    "    v_shift_factor=1,\n",
    "    figsize=[9, 5],\n",
    "    time_unit=\"yrs BP\",\n",
    ")\n",
    "ax[0].suptitle(\"Tree Rings\", y=1.2)\n",
    "\n",
    "# recall d18O is a proxy for SST, and that more positive d18O means colder SST\n",
    "ax = spel_stnd.stackplot(\n",
    "    label_x_loc=1.7,\n",
    "    xlim=[0, 2000],\n",
    "    v_shift_factor=1,\n",
    "    figsize=[9, 5],\n",
    "    time_unit=\"yrs BP\",\n",
    ")\n",
    "ax[0].suptitle(\"Speleothems\", y=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Questions 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Using the plots we just made (and recalling that all of these records are from Europe), let's make some inferences about the temperature data over the past 2,000 years:\n",
    "\n",
    "1.  Recall that &delta;<sup>18</sup>O is a proxy for SST, and that more positive &delta;<sup>18</sup>O means colder SST. Do the temperature records based on a single proxy type record similar patterns?\n",
    "2.  Do the three proxy types collectively record similar patterns?\n",
    "3.  What might be causing the more frequent variations in temperature?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/climate-course-content/tree/main/tutorials/W1D4_Paleoclimate/solutions/W1D4_Tutorial3_Solution_c2b80201.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Questions_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, we explored how to use the Euro2k proxy network to investigate changes in temperature over the past 2,000 years from tree rings, speleothems, and lake sediments. To analyze these diverse datasets, we categorized them based on their archive type and constructed time series plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Resources\n",
    "\n",
    "Code for this tutorial is based on an existing notebook from LinkedEarth that provides instruction on [working with LiPD files](https://github.com/LinkedEarth/PyleoTutorials/blob/main/notebooks/L1_working_with_LiPD.ipynb).\n",
    "\n",
    "Data from the following sources are used in this tutorial:\n",
    "\n",
    "- Euro2k database: PAGES2k Consortium., Emile-Geay, J., McKay, N. et al. A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088 (2017). https://doi.org/10.1038/sdata.2017.88\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W1D4_Tutorial3",
   "provenance": [
    {
     "file_id": "1lHuVrVtAW4fQzc0dFdlZuwY0i71KWw_t",
     "timestamp": 1677637469824
    }
   ],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}