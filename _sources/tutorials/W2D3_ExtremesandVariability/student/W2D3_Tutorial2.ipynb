{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neuromatch/climate-course-content/blob/main/tutorials/W2D3_ExtremesandVariability/student/W2D3_Tutorial2.ipynb) Â  <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/tutorials/W2D3_ExtremesandVariability/student/W2D3_Tutorial2.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tutorial 2: What is an Extreme Event? Empirical Return Levels\n",
    "\n",
    "**Week 2, Day 3, Extremes & Variability**\n",
    "\n",
    "**Content creators:** Matthias Aengenheyster, Joeri Reinders\n",
    "\n",
    "**Content reviewers:** Younkap Nina Duplex, Sloane Garelick, Paul Heubel, Zahra Khodakaramimaghsoud, Peter Ohue, Laura Paccini, Jenna Pearson, Agustina Pesce, Derick Temfack, Peizhen Yang, Cheng Zhang, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Content editors:** Paul Heubel, Jenna Pearson, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Production editors:** Wesley Banfield, Paul Heubel, Jenna Pearson, Konstantine Tsafatinos, Chi Zhang, Ohad Zivan\n",
    "\n",
    "**Our 2024 Sponsors:** CMIP, NFDI4Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "*Estimated timing of tutorial:* 30 minutes\n",
    "\n",
    "In this second tutorial, you will calculate the precipitation levels associated with the 50, 100, and 500-year events using the empirical method.\n",
    "\n",
    "By the end of this tutorial, you will have the ability to:\n",
    "\n",
    "- Calculate empirical return levels.\n",
    "- Visualize a data record using a return level plot.\n",
    "- Estimate the uncertainty qualitatively via bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 2068,
     "status": "ok",
     "timestamp": 1681923641610,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pooch\n",
    "import tempfile\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install and import feedback gadget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Install and import feedback gadget\n",
    "\n",
    "!pip3 install vibecheck datatops --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"comptools_4clim\",\n",
    "            \"user_key\": \"l5jpxuee\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W2D3_T2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Figure Settings\n",
    "import ipywidgets as widgets  # interactive display\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/neuromatch/climate-course-content/main/cma.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "\n",
    "def pooch_load(filelocation=None, filename=None, processor=None):\n",
    "    shared_location = \"/home/jovyan/shared/Data/tutorials/W2D3_ExtremesandVariability\"  # this is different for each day\n",
    "    user_temp_cache = tempfile.gettempdir()\n",
    "\n",
    "    if os.path.exists(os.path.join(shared_location, filename)):\n",
    "        file = os.path.join(shared_location, filename)\n",
    "    else:\n",
    "        file = pooch.retrieve(\n",
    "            filelocation,\n",
    "            known_hash=None,\n",
    "            fname=os.path.join(user_temp_cache, filename),\n",
    "            processor=processor,\n",
    "        )\n",
    "\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: What is an Extreme Event?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: What is an Extreme Event?\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "\n",
    "video_ids = [('Youtube', 'REkhPO9cZHs'), ('Bilibili', 'BV18V411N7Hk')]\n",
    "tab_contents = display_videos(video_ids, W=730, H=410)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_What_is_an_extreme_event_Video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"zx29a\"\n",
    "\n",
    "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_What_is_an_extreme_event_Slides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Section 1: Calculating Return Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The 100-year event represents a precipitation level that is expected to occur only once every 100 years, indicating an event with a 1% chance of occurring in any given year. Similarly, the 2-year event has a 50% chance of occurring annually. These return periods, as they are commonly referred to, play a crucial role in policymaking and infrastructure design. For instance, bridges are constructed to withstand 100-year flood events, evacuation plans are tailored for 50-year earthquakes, and nuclear power plants are engineered to withstand 10,000-year storms.\n",
    "\n",
    "To determine the return levels associated with a specific return period, there are two approaches: empirical calculation and the use of probability density functions (PDF) within a distribution. In this tutorial, we will first focus on the empirical method.\n",
    "\n",
    "First download and open the precipitation record in Germany (from the last tutorial) and plot it over time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 26698,
     "status": "ok",
     "timestamp": 1681923676549,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download file: 'precipitationGermany_1920-2022.csv'\n",
    "filename_precipitationGermany = \"precipitationGermany_1920-2022.csv\"\n",
    "url_precipitationGermany = \"https://osf.io/xs7h6/download\"\n",
    "data = pd.read_csv(\n",
    "    pooch_load(url_precipitationGermany, filename_precipitationGermany), index_col=0\n",
    ").set_index(\"years\")\n",
    "data.columns = [\"precipitation\"]\n",
    "precipitation = data.precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1681923683775,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precipitation.plot.line(\n",
    "    style=\".-\", xlabel=\"Time (years)\", ylabel=\"Annual Maximum Daily Precipitation \\n(mm/day)\",grid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here for a description of the plot  </font></summary>\n",
    "A time series of the annual maximum daily precipitation in millimeters per day per year. The data ranges from approximately 16 mm/day in the 1920s to almost 70 mm/day around 1970. About four peaks show unusual events of extreme precipitation (in 1924, 1968, 1982, and 2021). Moreover, a positive trend over time seems to be visible. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this tutorial, we will calculate the return period for each event in the dataset, specifically for each maximum precipitation value recorded in a given year. To accomplish this, we will begin by ranking the precipitation levels in descending order using the sort function. The sorted data will be saved in the first column of a matrix named \"precip\" with four columns, and the number of rows will correspond to the number of data entries.\n",
    "\n",
    "In the second column of the matrix, we will store the ranks assigned to each precipitation value, with the highest value assigned a rank of 1 and the lowest value assigned a rank corresponding to the total number of entries (e.g., 103)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681923686323,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a data frame from precipitation data\n",
    "precip_df = pd.DataFrame(index=np.arange(data.precipitation.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681923686323,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort the data\n",
    "precip_df[\"sorted\"] = np.sort(data.precipitation)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681923686680,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign the ranks\n",
    "precip_df[\"ranks\"] = np.arange(data.precipitation.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len() gives the length of the list\n",
    "len(precip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the command np.unique gives back only unique values, and len() gives the length.\n",
    "# Thus len(np.unique()) shows how many unique values can be found in the data in question.\n",
    "len(np.unique(precip_df[\"sorted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "Since we have 103 precipitation values but only 87 unique ones, we have a few instances where values are duplicated. It is important to ensure that these duplicate values are assigned the same rank. To address this, we can utilize the `rankdata` function from the `scipy` library. This function assigns similar values the same rank. After obtaining the ranks, we need to sort them before incorporating them into our matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681923688272,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank via scipy instead to deal with duplicate values\n",
    "precip_df[\"ranks_sp\"] = np.sort(stats.rankdata(-data.precipitation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the command set gives back only unique values.\n",
    "len(np.unique(precip_df[\"ranks_sp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, the length of ranks is the same as the length of unique values. \n",
    "Next we compute the empirical probability of exceedance by dividing the rank (r) by the total\n",
    "amount of values (n) plus 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681923688272,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find exceedance probability\n",
    "n = data.precipitation.size\n",
    "precip_df[\"exceedance\"] = precip_df[\"ranks_sp\"] / (n + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The return period and the chance of exceedance are related through T = 1/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681923689933,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find return period\n",
    "precip_df[\"period\"] = 1 / precip_df[\"exceedance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681923689933,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precip_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now that we know the return periods of each annual maximum precipitation level we can create\n",
    "a return level plot - a plot of return levels against return periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1681923690608,
     "user": {
      "displayName": "Matthias Aengenheyster",
      "userId": "16322208118439170907"
     },
     "user_tz": -60
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(precip_df[\"period\"], precip_df[\"sorted\"], \"o\")\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Return Period (years)\")\n",
    "ax.set_ylabel(\"Return Level (mm/day)\")\n",
    "ax.set_xscale(\"linear\")  # notice the xscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here for a description of the plot  </font></summary>\n",
    "A return level plot of the annual maximum precipitation data in millimeters per day versus the return period in years. The smaller the return period, the more data points we have, as these events are more likely. In contrast, events of a 10-year to a 100-year return period are rare in our 103-year-long dataset. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Frequently, we discuss return periods using a logarithmic scale, referring to events with return periods of 1 year, 10 years, and 100 years. Let's modify the plot above by changing the x-axis to a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(precip_df[\"period\"], precip_df[\"sorted\"], \"o\")\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Return Period (years)\")\n",
    "ax.set_ylabel(\"Return Level (mm/day)\")\n",
    "ax.set_xscale(\"log\")  # change the xscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Questions 1: \n",
    "\n",
    "1. From the figure, what is the return level associated with the 1, 10, and 100 year return periods.\n",
    "\n",
    "2. It is important to note that the plots we have just made represent a single data record, which means our estimate of \"extreme values\" relies on a limited number of data points. Considering this, how confident can we be about the return periods or levels of extreme values based on this plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "tags": []
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/climate-course-content/tree/main/tutorials/W2D3_ExtremesandVariability/solutions/W2D3_Tutorial2_Solution_ff3a3b57.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Questions_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Coding Exercise 1: \n",
    "\n",
    "We would like to have as much data as possible, because then we can sample more of what is possible, and be more sure we have not missed anything important. However, often we are limited by the available data, which is less than we would like.\n",
    "\n",
    "Fortunately, there is a trick that allows us to use the data itself to tell us about its own uncertainty. This method is called \"bootstrapping\", in reference to the saying of \"pulling oneself up by one's bootstraps\". \n",
    "\n",
    "This method works by assuming that while we have limited data, the data that we do have is nevertheless a representative sample of possible events - that is we assume that we did not miss anything systematic. Then, we use the data as a distribution to draw \"fake\" observations from, and compute uncertainties using those:\n",
    "\n",
    "1. We pull artificial observations from our data - with replacement.\n",
    "2. We draw as many observations as our data record is long. This record will now only include data points that we observed before, but some will show up several times, some not at all.\n",
    "3. We compute our statistics over this artifical record - just as we did to the record itself.\n",
    "4. We repeat this process many times.\n",
    "5. Thus we compute our statistics over many artificial records, which can give us an indication of the uncertainty.\n",
    "\n",
    "Remember, this only works under the assumption that our data is representative of the process - that we did not systematically miss something about the data. We cannot use this to estimate how hot it could get during noon if we only recorded the temperature at night. \n",
    "\n",
    "In this exercise, you may now:\n",
    "1. Define a function to calculate the empirical return period, then take 1000 resamples with replacement (each value could be sampled more than once) and plot the associated return level curves for each sample, together with the return period of the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# define a function to calculate the empirical return period by using the code from the cells above.\n",
    "# add period and sorted to a dataframe as before\n",
    "def empirical_period(data):\n",
    "    ...\n",
    "\n",
    "    return df[[\"period\", \"sorted\"]].set_index(\"period\")[\"sorted\"]\n",
    "\n",
    "\n",
    "# setup figure\n",
    "fix, ax = plt.subplots()\n",
    "\n",
    "# create 1000 resamples of the data, with replacement set to true.\n",
    "for i in range(1000):\n",
    "    ...\n",
    "\n",
    "# aesthetics\n",
    "ax.plot(precip_df[\"period\"], precip_df[\"sorted\"], \"ko\")\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"Return Period (years)\")\n",
    "ax.set_ylabel(\"Return Level (mm/day)\")\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "tags": []
   },
   "source": [
    "[*Click for solution*](https://github.com/neuromatch/climate-course-content/tree/main/tutorials/W2D3_ExtremesandVariability/solutions/W2D3_Tutorial2_Solution_8befc379.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=775.0 height=575.0 src=https://raw.githubusercontent.com/neuromatch/climate-course-content/main/tutorials/W2D3_ExtremesandVariability/static/W2D3_Tutorial2_Solution_8befc379_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<details>\n",
    "<summary> <font color='orangered'>Click here for a description of the plot  </font></summary>\n",
    "A return level plot of the annual maximum precipitation data in millimeters per day versus the return period in years. Additionally, the bootstrapped resamples are shown as associated return level curves. The smaller the return period, the more data points we have, and the narrower the uncertainty band. This is because these events are more likely and more often sampled in our original data. In contrast, events of a 10-year to a 100-year return period are rare in our 103-year-long dataset and corresponding return level curves show a larger spread. Hence, the uncertainty of return level increases for larger return periods, or in other words, for less likely events. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submit your feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Coding_Exercise_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Summary\n",
    "In this tutorial, you have explored how to calculate empirical return periods and visualized these using a return level plot. You also considered the limitations of estimating extreme values based on a single data record by applying a bootstrapping approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Resources\n",
    "\n",
    "Data from this tutorial uses the 0.25 degree precipitation dataset E-OBS. It combines precipitation observations to generate a gridded (i.e. no \"holes\") precipitation over Europe. We used the precipitation data from the gridpoint at 51 N, 6 E. \n",
    "\n",
    "The dataset can be accessed using the KNMI Climate Explorer [here](https://climexp.knmi.nl/select.cgi?id=someone@somewhere&field=ensembles_025_rr). The Climate Explorer is a great resource to access, manipulate and visualize climate data, including observations and climate model simulations. It is freely accessible - feel free to explore!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D3_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}